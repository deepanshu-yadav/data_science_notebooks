{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv( '../../../data_school_budget/school/TrainingData.csv' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Unnamed: 0            FTE         Total\n",
      "count  400277.000000  126071.000000  3.957220e+05\n",
      "mean   225186.018537       0.426794  1.310586e+04\n",
      "std    130025.142718       0.573576  3.682254e+05\n",
      "min         2.000000      -0.087551 -8.746631e+07\n",
      "25%    112601.000000       0.000792  7.379770e+01\n",
      "50%    225243.000000       0.130927  4.612300e+02\n",
      "75%    337722.000000       1.000000  3.652662e+03\n",
      "max    450340.000000      46.800000  1.297000e+08\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Create the histogram\n",
    "_= plt.hist(df['FTE'].dropna())\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high variance in expenditures makes sense (some purchases are cheap some are expensive). Also, it looks like the FTE column is bimodal. That is, there are some part-time and some full-time employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "LABELS = ['Function',\n",
    " 'Use',\n",
    " 'Sharing',\n",
    " 'Reporting',\n",
    " 'Student_Type',\n",
    " 'Position_Type',\n",
    " 'Object_Type',\n",
    " 'Pre_K',\n",
    " 'Operating_Status']\n",
    "\n",
    "\n",
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "df[LABELS] = df[LABELS].apply(categorize_label , axis =0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAFWCAYAAABkVZqwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xu4XGV5/vHvzUGCnJGoEQwgJ6EiAQNisRQBFbUeUfCEWK3RFhV/KBWpB5S2aBWsWovGIqJVBAVFUIsICKLI0QAiWFRC5aCgcoigSOD+/fGuCZPNzt4rYc96J3vuz3XNlVlrZtZ6spO9nlnv4Xllm4iIGF2r1A4gIiLqSiKIiBhxSQQRESMuiSAiYsQlEUREjLgkgoiIEZdEEBEx4pIIIiJGXBJBRMSIW612AG1stNFG3myzzWqHERGxUrnssst+a3vmZO9bKRLBZpttxqWXXlo7jIiIlYqkG9q8L01DEREjLokgImLEJRFERIy4JIKIiBGXRBARMeKSCCIiRlwSQUTEiEsiiIgYcSvFhLI2Njvsm1N2rIUffN6UHSsiYtjljiAiYsQlEUREjLgkgoiIEZdEEBEx4pIIIiJGXBJBRMSISyKIiBhxA0sEkmZIuljSFZKulvT+Zv/nJF0vaUHzmDOoGCIiYnKDnFB2L7Cn7T9IWh24QNK3m9cOtf3VAZ47IiJaGlgisG3gD83m6s3DgzpfRESsmIH2EUhaVdIC4FbgLNsXNS/9i6QrJX1U0hrL+Ow8SZdKuvS2224bZJgRESNtoInA9v225wCbALtIehLwLuCJwM7AhsA7l/HZ+bbn2p47c+bMQYYZETHSOhk1ZPsO4HvAPrZvcXEvcDywSxcxRETE+AY5amimpPWb52sCewPXSprV7BPwIuAng4ohIiImN8hRQ7OAEyStSkk4J9s+Q9I5kmYCAhYAbxpgDBERMYlBjhq6EthxnP17DuqcERGx/DKzOCJixCURRESMuCSCiIgRl0QQETHikggiIkZcEkFExIhLIoiIGHFJBBERIy6JICJixCURRESMuCSCiIgRl0QQETHikggiIkZcEkFExIhLIoiIGHFJBBERIy6JICJixCURRESMuCSCiIgRN7BEIGmGpIslXSHpaknvb/ZvLukiSddJOknSIwYVQ0RETG7SRCBpN0lrNc9fLekYSZu2OPa9wJ62dwDmAPtI2hX4EPBR21sBtwOvX/HwIyLi4WpzR3AscI+kHYB/BG4APj/Zh1z8odlcvXkY2BP4arP/BOBFyxt0RERMnTaJYLFtAy8EPmb7Y8A6bQ4uaVVJC4BbgbOAXwB32F7cvOVGYONlfHaepEslXXrbbbe1OV1ERKyANolgkaR3AQcA35S0KuXb/aRs3297DrAJsAuw7XhvW8Zn59uea3vuzJkz25wuIiJWQJtEsD+lvf91tn9N+Qb/4eU5ie07gO8BuwLrS1qteWkT4OblOVZEREytSRNBc/E/BVij2fVb4GuTfU7STEnrN8/XBPYGrgHOBV7avO1A4LTlDzsiIqZKm1FDb6B07n662bUx8PUWx54FnCvpSuAS4CzbZwDvBA6R9HPgUcBxKxJ4RERMjdUmfwsHUdr3LwKwfZ2kR0/2IdtXAjuOs/+XzfEiImIItOkjuNf2n3sbTfv+uB28ERGx8mmTCM6TdDiwpqRnAl8BTh9sWBER0ZU2ieAw4DbgKuCNwLeAdw8yqIiI6M6kfQS2HwA+0zwiImKamTQRSLqecfoEbD9hIBFFRESn2owamtv3fAbwMmDDwYQTERFdazOh7Hd9j5ts/zulcFxEREwDbZqGdurbXIVyh9Cq6FxERAy/Nk1DR/c9XwwsBPYbSDQREdG5NqOGntFFIBERUccyE4GkQyb6oO1jpj6ciIjo2kR3BOkHiIgYActMBLbf32UgERFRR5tRQzMoC8z/BWUeAQC2XzfAuCIioiNtag19AXgs8GzgPMqqYosGGVRERHSnTSLY0vZ7gLttnwA8D9h+sGFFRERX2iSC+5o/75D0JGA9YLOBRRQREZ1qM6FsvqQNgPcA3wDWbp5HRMQ00CYRHG/7fkr/QCqORkRMM22ahq6XNF/SXpLU9sCSHi/pXEnXSLpa0sHN/iMk3SRpQfN47gpHHxERD1ubRLAN8F3KIvYLJf2HpKe3+Nxi4O22twV2BQ6StF3z2kdtz2ke31qhyCMiYkq0KUP9R9sn234JMAdYl9JMNNnnbrF9efN8EXANsPHDjDciIqZYmz4CJP01sD/wHOASlrP6qKTNgB2Bi4DdgDdLeg1wKeWu4fZxPjMPmAcwe/bs5TldxLR19P5/M2XHevtJZ0zZsWLlNukdQbNU5duA7wNPsr2f7VPankDS2sApwNts3wUcC2xBubu4haXLXC9he77tubbnzpw5s+3pIiJiObW5I9ihuYAvN0mrU5LAF22fCmD7N32vfwbI15KIiIra9BGsaBIQcBxwTX/Jakmz+t72YuAnK3L8iIiYGq36CFbQbsABwFWSFjT7DgdeIWkOYMpqZ28cYAwRETGJgSUC2xcA4807yHDRiIgh0qaz+DGSjpP07WZ7O0mvH3xoERHRhTYTyj4HnAk8rtn+X8ooooiImAbaJIKNbJ8MPABgezFw/0CjioiIzrRJBHdLehSlcxdJuwJ3DjSqiIjoTJvO4kMo5ae3kPQDYCbw0oFGFRERnZk0Edi+vCkxsQ1lFNDPbN83ycciImIl0Wbx+teM2bWTJGx/fkAxRUREh9o0De3c93wGsBdwOZBEEBExDbRpGnpL/7ak9YAvDCyiiIjoVJtRQ2PdA2w11YFEREQdbfoITqcZOkpJHNsBJw8yqIiI6E6bPoKP9D1fDNxg+8YBxRMRER1r00cw6bKUERGx8mrTNLSIB5uGlnoJsO11pzyqiIjoTJumoY8Cv6aMFBLwKmAd2/82yMAiIqIbbUYNPdv2f9peZPsu28cC+w46sIiI6EabRHC/pFdJWlXSKpJeRaqPRkRMG20SwSuB/YDfNI+XNfsiImIaaDNqaCHwwsGHEhERNSwzEUj6R9v/JukTjDNqyPZbJzqwpMdT6hE9lrKozXzbH5O0IXASsBll8fr9bN++wn+DiIh4WCa6I7im+fPSFTz2YuDtTRnrdYDLJJ0FvBY42/YHJR0GHAa8cwXPERERD9MyE4Ht05s/T1iRA9u+Bbileb5I0jXAxpRmpj2at50AfI8kgoiIatpMKNsaeAelKWfJ+23v2fYkkjYDdgQuAh7TJAls3yLp0cv4zDxgHsDs2bPbnioiIpZTmwllXwE+BfwXKzBsVNLawCnA22zfJanV52zPB+YDzJ07d7yZzRERMQXaJILFzSSy5SZpdUoS+KLtU5vdv5E0q7kbmAXcuiLHjoiIqdFmHsHpkv5B0ixJG/Yek31I5av/ccA1to/pe+kbwIHN8wOB05Y76oiImDJt7gh6F+1D+/YZeMIkn9sNOAC4StKCZt/hwAeBkyW9Hvg/ygS1iIiopM2Ess1X5MC2L6AUqRvPXityzIiImHptRg29Zrz9trN4fUTENNCmaWjnvuczKN/mL6fMGo6IiJVcm6aht/RvS1qPsjZBRERMA21GDY11D7DVVAcSERF1tOkjOJ0Hi86tAmwHnDzIoCIiojtt+gg+0vd8MXCD7RsHFE9ERHSsTR/BeV0EEhERdaxIH0FEREwjSQQRESNumYlA0tnNnx/qLpyIiOjaRH0EsyT9NfACSV9mTLkI25cPNLKIiOjERIngvZRlJDcBjhnzmoHWC9NERMTwmmipyq8CX5X0HttHdhhTRER0qM3w0SMlvQDYvdn1PdtnDDasiIjoyqSjhiQdBRwM/LR5HNzsi4iIaaDNzOLnAXNsPwAg6QTgx8C7BhlYRER0o+08gvX7nq83iEAiIqKONncERwE/lnQuZQjp7uRuICJi2mjTWXyipO9RFqgR8E7bvx50YBER0Y1WTUO2b7H9DduntU0Ckj4r6VZJP+nbd4SkmyQtaB7PXdHAIyJiagyy1tDngH3G2f9R23Oax7cGeP6IiGhhYInA9vnA7wd1/IiImBoTJgJJq/Q37UyRN0u6smk62mCCc8+TdKmkS2+77bYpDiEiInomTATN3IErJM2eovMdC2wBzAFuAY6e4Nzzbc+1PXfmzJlTdPqIiBirzfDRWcDVki4G7u7ttP2C5T2Z7d/0nkv6DJBSFRERlbVJBO+fqpNJmmX7lmbzxcBUNztFRMRyarVmsaRNga1sf1fSI4FVJ/ucpBOBPYCNJN0IvA/YQ9IcShnrhcAbH0bsERExBSZNBJLeAMwDNqS0728MfArYa6LP2X7FOLuPW4EYIyJigNoMHz0I2A24C8D2dcCjBxlURER0p00iuNf2n3sbklajNO1ERMQ00CYRnCfpcGBNSc8EvgKcPtiwIiKiK20SwWHAbcBVlM7dbwHvHmRQERHRnTajhh5oFqO5iNIk9DPbaRqKiJgm2owaeh5llNAvKGWoN5f0RtvfHnRwERExeG0mlB0NPMP2zwEkbQF8E0giiIiYBtr0EdzaSwKNXwK3DiieiIjo2DLvCCS9pHl6taRvASdT+gheBlzSQWwREdGBiZqGnt/3/DfAXzfPbwOWWT46IiJWLstMBLb/tstAIiKijjajhjYH3gJs1v/+FSlDHRERw6fNqKGvU4rFnQ48MNhwIiKia20SwZ9sf3zgkURERBVtEsHHJL0P+A5wb2+n7csHFlVERHSmTSLYHjgA2JMHm4bcbEdExEquTSJ4MfCE/lLUERExfbRJBFcA65PZxBExjhsP+/6UHWuTD/7VlB0r2muTCB4DXCvpEpbuI8jw0YiIaaBNInjfihxY0meBv6HUKnpSs29D4CTKnISFwH62b1+R40dExNSYtOic7fPGe7Q49ueAfcbsOww42/ZWwNnNdkREVDRpIpC0SNJdzeNPku6XdNdkn7N9PvD7MbtfCJzQPD8BeNFyRxwREVOqzQpl6/RvS3oRsMsKnu8xtm9pjnuLpEcv642S5gHzAGbPnr2Cp4uIiMm0WY9gKba/TgdzCGzPtz3X9tyZM2cO+nQRESOrTdG5l/RtrgLMpUwoWxG/kTSruRuYRYakRkRU12bUUP+6BIspo31euILn+wZwIPDB5s/TVvA4ERExRdr0EazQugSSTgT2ADaSdCNlGOoHgZMlvR74P8pqZxERUdFES1W+d4LP2faREx3Y9iuW8dJebQKLiIhuTHRHcPc4+9YCXg88CpgwEUSs7D75pnOm7FgHfSo1GmN4TbRU5dG955LWAQ4G/hb4MnD0sj4XERErlwn7CJqSEIcAr6JMANspJSEiIqaXifoIPgy8BJgPbG/7D51FFRERnZloQtnbgccB7wZu7iszsahNiYmIiFg5TNRHsNyzjmOMI9abwmPdOXXHiojok4t9RMSISyKIiBhxSQQRESMuiSAiYsQlEUREjLgkgoiIEZdEEBEx4pIIIiJGXBJBRMSISyKIiBhxSQQRESMuiSAiYsQlEUREjLhJF68fBEkLgUXA/cBi23NrxBEREZUSQeMZtn9b8fwREUGahiIiRl6tOwID35Fk4NO25499g6R5wDyA2bNndxze9Lb9CdtPyXGuOvCqKTlORNRV645gN9s7Ac8BDpK0+9g32J5ve67tuTNnzuw+woiIEVElEdi+ufnzVuBrwC414oiIiAqJQNJaktbpPQeeBfyk6zgiIqKo0UfwGOBrknrn/5Lt/6kQR0REUCER2P4lsEPX542IiPFl+GhExIhLIoiIGHFJBBERIy6JICJixCURRESMuJpF5yKWuOaJ207Jcba99popOU6s/I444oihOg7A2edsMSXH2WvPX0zJcXpyRxARMeKSCCIiRlwSQUTEiEsiiIgYcUkEEREjLokgImLEJRFERIy4JIKIiBGXRBARMeKSCCIiRlwSQUTEiEsiiIgYcUkEEREjrkoikLSPpJ9J+rmkw2rEEBERReeJQNKqwCeB5wDbAa+QtF3XcURERFHjjmAX4Oe2f2n7z8CXgRdWiCMiIgDZ7vaE0kuBfWz/XbN9APBU228e8755wLxmcxvgZ1MUwkbAb6foWFMlMbWTmNobxrgSUztTGdOmtmdO9qYaK5RpnH0PyUa25wPzp/zk0qW25071cR+OxNROYmpvGONKTO3UiKlG09CNwOP7tjcBbq4QR0REUCcRXAJsJWlzSY8AXg58o0IcERFBhaYh24slvRk4E1gV+KztqzsMYcqbm6ZAYmonMbU3jHElpnY6j6nzzuKIiBgumVkcETHikggiIkZcEkFExIhLIoiIGHEjkwgkbSzpLyXt3nsMQUxrStqmdhwRgyZpjSGI4ZkTvPahLmOZiKRVJK3b5TlHIhE0/8g/AN4NHNo83lE5pucDC4D/abbnSKo6n0LSx8d5HCmpWi0oSYsk3TXm8StJX5P0hEoxbSnpTElXNNtPlvSuGrEMe1ySdpF0FXBds72DpE9UCueTkp7Xv6O56H4O2KFOSEvi+JKkdSWtBfwU+JmkQ7s6/0gkAuBFwDa2n2v7+c3jBZVjOoJSgO8OANsLgM0qxgMwA5hD+aW9DngysCHwekn/XimmYyiJe2PKLPR3AJ+hFCv8bKWY/gt4P/BAs30V8OpKsfQbxrg+DvwN8DsA21cAz6gUy7OAoyW9BEDSDMpk1tWB51eKqWc723dRrlXfAmYDB3R18hq1hmr4JeUf+97agfRZbPtOabzSS9VsCexpezGApGOB7wDPpFxUatjH9lP7tudL+pHtD0g6vFJMa9n+Ye/fzrYl3Vcpln7DGNcqtm8Y8//8/hqB2F4oaW/gTEmPplxoL7J9SI14xlhd0uqURPAftu+T1Nkkr1FJBPcACySdTV8ysP3WeiHxE0mvBFaVtBXwVuCHFeOB8q17LeDOZnst4HG275dUK4k+IGk/4KvN9kv7Xqs1G/J3kjbvnV/Si4BfV4ql3zDG9StJuwBu1iJ5C/C/NQKRtFPz9B+BzwNnAf/d22/78hpxNT4NLASuAM6XtClwV1cnH4mZxZIOHG+/7RO6jqVH0iOBf6LcropScuNI23+qGNPrKf0o32ti2h34V+BE4AjbnbVZ9sX0BOBjwNMoF7gfAf8PuAl4iu0LKsS0JaUMwK7AbcAtwMttL+w6lmGPq/nm/XFgb8r/qbOAN9vuvPSzpHMneNm29+wsmBYkrda7Ox/4uUYhEQA0Be62bjZ/Zrv2LfMSzTeltZo2wtqxzKL0XQi42HYqwy6DpPUov0N31I6l37DGtbKQ9EzbZ3V8zveOt9/2B7o4/0h0Fkvag9L5+UngP4H/rT18dMwogavpeJTABFahfJv8PbDlEPycZko6XNJ8SZ/tPSrHtIGkYyjfbs+UdLSkDWrGNKxxSdqsGeH16+ZxiqTNasbUQo2hpHf3Pe6nLOW7WVcnH4k7AkmXAa+0/bNme2vgRNtPqRjTAttzJL0KeArwTuAy20+uGNOHgP0piak38sQ1R1hJ+iHwfeAy+joZbZ9SMaYzKU1U/93seiWwm+1n1YoJhjMuSRdSmqu+2BfTG20/rVZMk5H0Y9s7Vo5hDeAbtp/dxflGpbN49V4SALD9v00PfU1VRwksQ2+Y7TCNrnqk7XfWDmKMjWy/r2/7/c2XjdqGMa5VbB/ft/05SX9fLZp2av8eAjwS6GyezEg0DQGXSjpO0h7N4zOUb5g1fQq4njIyp/NRAsvQG2Y7TM6Q9NzaQYxxnsra2wA049K/XTGenmGM6xxJ75C0icrs/kOA05tm0U5nzw4zSVdJurJ5XE1Zo/3jnZ1/RJqG1gAOAp5O6QQ9H/jPGt98m1+EJZuUbx+3ARcAv+pqlMB4JJ1CmWE5NMNsJS2iJMt7gftofma2q11EJN0OrNfEY+ARPDjk1rY3TFxLYvrVBC/b9uzOgmlJ0qm2X9LxOTft21wM/KbLa8FIJIJhIul94+zeEHg2ZYjmlzsOaYlhHGY7jJpRXstku8qEqWGNa9g0Q7ffDsy2/YZmHs82ts+oGNMXbB8w2b6BnX86JwJJJ9veT6XWyUP+ojU7ZseStCHwXds7TfrmESDpibav7ZsEtJSak38k9cpbnOUh+gUaxrgk/YgS04m2F9WOB0DSSZSm4dfYfpKkNYELbc+pGNPl/b/7klYDrrS9XSfnH5L/LwMhaZbtW8bcdi1h+4auY5pIrdEKw5gwJc23PW8Zk4CqTv6RtA/wt8BOwEnA52z/vFY8PcMYl6QnNjG9jDJz/njbZ1eO6VLbc/t/3yRdYbvzwnMqRQEPB9akVECA0vz5Z2C+7W6KBtqe9g/gQ232VY5xT+CcSuee1fy56XiPyj+XGW32VYptA+DNwK8o/U4HAKslrnFjWhV4MWVG+PXAe4D1K8XyQ8qF9/JmewvK5MmaP5+jap5/Wt8R9Iy97Wr2Xek633TH+9a9IXAz5Vb12q5jgiXty2fa3rvG+ZdlGf92D9nXtWai1iuB1wC/Bb5EGYywVc2f4TDGJWk7yl3B84FzKHMKng7sX+PfUWVdgncD21GKKu4GvNb297qOZUxcGwBbUaoAA2D7/C7OPa3nETTjlf8B2ELSlX0vrUO9Am9/M2bbwO9s310jmCVBlMJy90haz/adk39isCQ9llIEb01JO1JulwHWpYyxrkbSycD2lIvsvrZvbF76oqQfJ66lYroI+COln+C9tv/YvPQDSbtViEfAtcBLKDWZBBzsCrWPxsT1d8DBlFLrC5rYLqS0FAz+/NP5jkCl5soGwFHAYX0vLbL9+zpRDa/mQrIrpUTBksTkCsNHmxFMrwXmApfwYCK4CzjB9qkVYtrV9o8kPYvh6pAdurgkvcT2qZK2tl2l2uiySLrMFasKjKdpKdgZ+JFLxYEnAu+3vX8n5x+C/zMDJ2lX4Go3oxYkrUNZCOKiupENl2EbPippFeAVtr846Zs7MAxNUuMZxriGMaYeSZ+kdKRfUjuWHkmX2N5Z0gLgqbbvVVOGpovzT+umoT7HUkZS9Nw9zr6RV+uCvyy2H5D0Rh6sUxMxFZ4BvEnSQsq1oDdJseZw8hslrQ98HTirmRzYWeXfUbkjeEhmrdVZPMyaiTVHUTrR+jusqqwN3MT0Hkob80ks3VzVedOepDsoo3DG5UrF+YYxLkn3AOMNXa1+0R324eSS/poyQ/zb7qhc/qjcEfxS0lspdwFQOpB/WTGeYXU88D7go5RvTX/Lg23ztbyu+fOgvn2mw4JcfW4Djq5w3skMY1zXU38d4KWorFH8JsqSrFcBx7liSZd+/bOIbZ/X20dH6xaPyh1Bb5WkPSkXkbOBt9m+tWpgQ6bXiSbpKtvbN/u+b/uvasc2DIa13XsY46o1OXIizYzi+yhlzZ8D3GD74LpRFePMLF4VuModzSweiTuC5oL/8tpxrAT+1HTQXifpzZTJP4+uGZBKqe6/pyybCWUZzU93dcs8xsI2b1L3K1wtbPOmjuP6QZs3STqww76p7fq+4BwHXNzReZepf2axpF714SUzizuLY0TuCGYCb6Cs+LMk+dl+3bI+M4ok7QxcA6wPHElpp/w32z+qGNN/UUpj9y4WBwD32/67WjFNZhi/ocNwxtVlTON86x6an4eko9xVOYlxjMQdAXAa5Xbwu/StchVL6xtO9wdK/8Aw2NlL14A5R9IV1aJpp3a/yrIMY1xdxrTDmG/dvW/h1UqbNx3Xd/SSgKRnUBaIWgh80vafu4hjVBLBMK5yNXRUlvA8lFJjqP/OqVqBN+B+SVvY/gWApCcw/Ml8WG+zhzGuzmKyPWGZ7kpOptRgulPSHOArlJF7cyjrq3dy5zsqieAMSc+1/a3agQy5r1BWTvsMw3OxPRQ4V9IvKd/cNmV47lbi4RvGu5QurWm7N1/g1cBnbR/d9NUt6CqIUUkEBwOHSxqaVa6G1GLbx07+tu7YPruZ37AN5d/tWldeU1nSGmNjGLNvYfdRtbKw6xNK2tz29RPsa9WpPI31J8I9gXfBksmU3QUxCp3FMTGVRXEA3grcCnyNpZeqrFaXqRn7/Q+UapWm9PV8yvafKsY0lBVRmzj+kocOivh8xXjG+1kNXa2fWiR9DJgF3AK8ANja9n2SZgGn257bRRwjcUcgaffx9ndV4nUlcBnlItv7CvKOMa9Xm1kMfB5YBHyi2X4F8AXKQiedGuaKqLBkAtIWlCaFXtOeKT/DrmN5IvAXwHqS+tf/XZe+WevB24D9Kcng6X3Doh8L/FNXQYxEIqC0M/fMAHahXPxqdoIOk/2BX9m+BZYUn9uX0pRwRL2wgLKWbP+ooXMrjhp6NqUi6ibAMX37F1HGgtc2lzJWfhhu87ehlFxfn6VnGC+iDOUOSvs08JB1ym0vVTZc0oW2nzaoOEYiEdheaqq7pMcD/1YpnGH0KWBvWHL3dBTwFsrIhfnAS+uFxo97ZZab+J5KpXblZuLTCZL2tX1KjRgm8RPKN8lbagdi+zTgNElPs31h7XimgYHeRY1EIhjHjcCTagcxRFbt6wfYn7JW6inAKU1Z3JqeCrxG0v8127OBa5r67bWKl50h6ZU8tC3+AxVi6bcR8FNJF7N0H0+VYniNN0m6xvYdsGQVrqMzmXO5DfQubyQSgaRP8OAPchXKN91hn5TUpVUlrdYU4NoLmNf3Wu3/I/tUPv94TgPupDQvVh3BNMYRtQMYx5N7SQDA9u1N/0oMkdq/5F25tO/5YuBE26M+bK3ficB5kn5LKfn8fQBJW1IueNXYvkFSb83d4yVtBKwzdkhixzaxPXQJyvZ5kh5DWekKyoLstQsrriJpA9u3w5IRaqNy3ZlKAx1LOq2Hj0qabfv/Jn9nNKu4zQK+42b95Gam8dq2L68Y1/sonaDb2N5a0uOAr9jufL3bvpjmA5+wfVWtGMYjaT/gw5TCfAL+CjjU9lcrxvQaytj4r1LuyvcD/sX2F2rFtDKS9CTbPxnY8ad5IlgyhlnSKbb3rR1TLJ+mj2JH4PJeWePaiwpJ+imlpv31lKah6outNHFdATyzdxfQFFv87phRVzXi2o4yQk/A2bZ/WjOeYSRpEQ/tB7iT0prxdtsDXT9lut+i9d9O1RwLHyvuz7YtyQCS1qodEKWW/TBaZUxT0O8N3yxjAAAJl0lEQVQofWK1bQjc3TTtzRxvtnFwDGVpyi9Rrlsvp4wA+xnwWWCPQZ58GP6TDJKX8TxWHidL+jSwvqQ3UCrI/lfNgJolDR8P7Nk8v4fh+F36H0lnSnqtpNcC3wSq1tdqmvbeSVM6gVJS/L/rRTS09rH9aduLbN9lez7wXNsnARsM+uTT/Y6gV3a2v+QspNbQSsP2RyQ9E7iLMknpvR0v+vIQ/f0WlOU9exe3av0WALYPlbRvE4cow4C/VjMmSmXNHYHLAWzfLGmduiENpQeaPp5ef07/3J2Bf4md1olgSMvOxnJqLvxnQVnCT9KrbH+xYkhDe3Hrzf+oHUefYWzaG0avAj5GKT1t4EfAqyWtCbx50Cef1okgVl6S1qUsWL8x8A1KIjiIUi5kAVAzEQzVxU3SBbafPk6H4zDc+Y5t2nsdpcx59Gk6g5+/jJcvGPT5p/WooVh5SToNuB24kDLJbQPgEcDBtqvOdpb0DmAr4JmUchyvA75k+xMTfnBENU17z6IkpjNrN+0No9rL6SYRxFCSdJUfXGh8VeC3wGzbi+pGVgzjxU3SF2wfMNm+GD6SfkiZyHkZfYtCdVXTKk1DMax65Xixfb+k64clCcDS/RZD5C/6NyStBlSp+z9Bc1XP74AP2/7PjkMbVlWX080dQQwlSfcDd/c2gTUpwzRrLjS+rIsaALXa4iW9i1IGu/czgvJz+jNl5NC7lvXZWiQ9Cvih7W1qxzIMJP0z5edRZbhvEkHEcpL0AeDXlAVyRBnxsY7tqqXNJR01pBf9nXhwhbkLerX2Jc3qrYEx6povGWtRZqp3vpxuEkHEcpJ0ke2nTravw3ieaPva5oL7EJVrRb2Xsprcqc2uF1FqRf1zrZjioZIIIpZT07H3ScrKUqYsn3mQ7b+sFM982/MknTvOy7ZdbSU+SdcAO7pZY7oZF3+57W1rxTRMhiWJp7M4Yvm9kjL552OURPCDZl8Vtuc1fz6jVgwTWEhZXetPzfYawC+qRTN8DqGs/3H0OK+ZjpbTzR1BxDQh6WXA/9heJOndwE7AkR6z/m1HsfQWg5pNWR+hN8Jqb0o/wcu7jmmYSZrRu2uaaN/Azp9EELF8JB3POKOHai+/2CvP3SzkcxTwEeDwGn0Xkg5snq5JqcX0AGV8/B9hyfrP0egvmT/RvkFJ01DE8juj7/kMSu2hmyvF0q83Eel5wLG2T5N0RKVYvgT8C2XW9Q2U6qyPpxTpO7xSTENH0mMpZVTWbJbw7JXOXxd4ZGdx5I4g4uGRtAplAZhqnbJNHGcAN1GaX55C+fZ9cY2FaSR9FFgbOKQ3EbCpH/UR4B7bb+s6pmHU3Dm9llLNtn9J3UXA52yfOt7npjyOJIKIh0fSNsA3bW9ZOY5HAvsAV9m+TtIsYHvb36kQy3XA1h5zgWnKhVxre6uuYxpmkvbtqpzEeNI0FLGcxplh/GvK4itV2b5H0i+AZ0t6NvD9GkngwXAe+i2zKReSb59j2D5F0vMoZUJm9O3/QBfnH4ZVlSJWKrbXsb1u32Prmt/meiQdTCnP/ejm8d+S3lIpnJ82C9cvRdKrgWsrxDPUJH0K2B94C6Wf4GXApp2dP01DEctH0tm295psX9ckXQk8zfbdzfZawIW2n1whlo0ps4n/SKmoacow0jWBF9u+qeuYhlnfiK/en2sDp9p+VhfnT9NQREuSZlBGcmwkaQOWHuHxuGqBPUj0lTBunmsZ7x2o5kL/VEl7Upo7BHzb9tk14lkJ9OYL3CPpcZTqrJt3dfIkgoj23gi8jXLRv6xv/yJKyYnajgcuktRbp/hFwHEV48H2OcA5NWNYSZwuaX3gw5QlUE2HK7mlaSiiJUk7AzcCL7X9iWbo376UMgpH2P59zfhgqUqfAs6vMas4lk8z/HhX2z9sttcAZti+s7MYkggi2pF0ObC37d9L2p1SdO4twBxgW9svrRTXDOBNwJbAVcBxthfXiCVWjKQLbT+t1vkzaiiivVX7vvXvT1n05RTb76FchGs5gTIh6SrgOZRJW7Fy+Y6kfSVV6dNJH0FEe6tKWq35tr0XpWpkT83fpe361nc+Dri4YiyxYg6hLExzv6Q/0vHCNEkEEe2dCJwn6beUYZHfB5C0JdBZe+44+td3XlzpS2U8DLbXqXn+9BFELAdJuwKzgO/0jdffGli71kpgw7i+cyyfpknoVcDmto+U9Hhglu1O7u6SCCIiKpN0LKVU9562t23mqXzH9s5dnD9NQxER9T3V9k6Sfgxg+3ZJj+jq5Bk1FBFR331NZVYDSJpJuUPoRBJBRER9Hwe+BjxG0r8AFwD/2tXJ00cQETEEJD2RMiwZ4Bzb13R17vQRREQMh0cCveahNbs8cZqGIiIqk/ReygzxDYGNgOMlvbuz86dpKCKiLknXADva/lOzvSZwue1tuzh/7ggiIupbSN8SlcAawC+6OnnuCCIiKpP0dcoKbmc1u/amjBy6FcD2Wwd5/nQWR0TUdyZwNmXuwP3AuV2ePIkgIqISSatR5gu8DriB0lz/eMpqc4fbvm+Cj0+Z9BFERNTzYcpIoc1tP8X2jsATgPWa1zqRPoKIiEokXQds7TEX4qbcxLW2t+oijtwRRETU47FJoNl5P03doS4kEURE1PNTSa8Zu1PSq4FruwoiTUMREZVI2hg4lbLi3WWUu4CdKSUmXmz7pk7iSCKIiKhL0p7AX1BWlbva9tmdnj+JICJitKWPICJixCURRESMuCSCGHmS/rAc7z1C0jsGdfyIGpIIIiJGXBJBxDgkPV/SRZJ+LOm7kh7T9/IOks6RdJ2kN/R95lBJl0i6UtL7xznmLEnnS1og6SeS/qqTv0zEJJIIIsZ3AbBrU/vly8A/9r32ZOB5wNOA90p6nKRnAVsBuwBzgKdI2n3MMV8JnGl7DrADsGDAf4eIVlJ9NGJ8mwAnSZoFPAK4vu+102z/EfijpHMpF/+nA88Cfty8Z21KYji/73OXAJ+VtDrwddtJBDEUckcQMb5PAP9he3vgjSy9etTYyTemTAQ6yvac5rGl7eOWepN9PrA7cBPwhfFKC0TUkEQQMb71KBdsgAPHvPZCSTMkPQrYg/JN/0zgdZLWhlI6QNKj+z8kaVPgVtufAY4Ddhpg/BGtpWkoAh4p6ca+7WOAI4CvSLoJ+BGwed/rFwPfBGYDR9q+GbhZ0rbAhZIA/gC8mmapwcYewKGS7mtezx1BDIWUmIiIGHFpGoqIGHFJBBERIy6JICJixCURRESMuCSCiIgRl0QQETHikggiIkbc/wd0/r+wiKWkWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = df[LABELS].apply(  pd.Series.nunique ,  axis =0)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot( kind = 'bar' )\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).any():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function_Aides Compensation</th>\n",
       "      <th>Function_Career &amp; Academic Counseling</th>\n",
       "      <th>Function_Communications</th>\n",
       "      <th>Function_Curriculum Development</th>\n",
       "      <th>Function_Data Processing &amp; Information Services</th>\n",
       "      <th>Function_Development &amp; Fundraising</th>\n",
       "      <th>Function_Enrichment</th>\n",
       "      <th>Function_Extended Time &amp; Tutoring</th>\n",
       "      <th>Function_Facilities &amp; Maintenance</th>\n",
       "      <th>Function_Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Object_Type_Rent/Utilities</th>\n",
       "      <th>Object_Type_Substitute Compensation</th>\n",
       "      <th>Object_Type_Supplies/Materials</th>\n",
       "      <th>Object_Type_Travel &amp; Conferences</th>\n",
       "      <th>Pre_K_NO_LABEL</th>\n",
       "      <th>Pre_K_Non PreK</th>\n",
       "      <th>Pre_K_PreK</th>\n",
       "      <th>Operating_Status_Non-Operating</th>\n",
       "      <th>Operating_Status_Operating, Not PreK-12</th>\n",
       "      <th>Operating_Status_PreK-12 Operating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Function_Aides Compensation  Function_Career & Academic Counseling  \\\n",
       "0                            0                                      0   \n",
       "1                            0                                      0   \n",
       "\n",
       "   Function_Communications  Function_Curriculum Development  \\\n",
       "0                        0                                0   \n",
       "1                        0                                0   \n",
       "\n",
       "   Function_Data Processing & Information Services  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "\n",
       "   Function_Development & Fundraising  Function_Enrichment  \\\n",
       "0                                   0                    0   \n",
       "1                                   0                    0   \n",
       "\n",
       "   Function_Extended Time & Tutoring  Function_Facilities & Maintenance  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "\n",
       "   Function_Facilities Planning                 ...                  \\\n",
       "0                             0                 ...                   \n",
       "1                             0                 ...                   \n",
       "\n",
       "   Object_Type_Rent/Utilities  Object_Type_Substitute Compensation  \\\n",
       "0                           0                                    0   \n",
       "1                           0                                    0   \n",
       "\n",
       "   Object_Type_Supplies/Materials  Object_Type_Travel & Conferences  \\\n",
       "0                               0                                 0   \n",
       "1                               0                                 0   \n",
       "\n",
       "   Pre_K_NO_LABEL  Pre_K_Non PreK  Pre_K_PreK  Operating_Status_Non-Operating  \\\n",
       "0               1               0           0                               0   \n",
       "1               1               0           0                               1   \n",
       "\n",
       "   Operating_Status_Operating, Not PreK-12  Operating_Status_PreK-12 Operating  \n",
       "0                                        0                                   1  \n",
       "1                                        0                                   0  \n",
       "\n",
       "[2 rows x 104 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(  df[LABELS]   , prefix_sep = '_')\n",
    "\n",
    "dummies.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 0 to 400276\n",
      "Data columns (total 2 columns):\n",
      "FTE      320222 non-null float64\n",
      "Total    320222 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 4 to 400274\n",
      "Data columns (total 2 columns):\n",
      "FTE      80055 non-null float64\n",
      "Total    80055 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 0 to 400276\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 4 to 400274\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the new DataFrame: numeric_data_only\n",
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS] , prefix_sep = '_')\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only, label_dummies  , size=0.2, seed= 123 )  \n",
    "                                                    \n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Create the DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier( LogisticRegression() )\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train , y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test\n",
    ", y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepanshu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit it to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Load the holdout data: holdout\n",
    "holdout = pd.read_csv( '../../../data_school_budget/school/TestData.csv'  , index_col = 0 )\n",
    "\n",
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions: predictions\n",
    "\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=\n",
    "                          pd.get_dummies(df[LABELS]).columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "#prediction_df.to_csv('predictions.csv')\n",
    "\n",
    "# # Submit the predictions for scoring: score\n",
    "# score = score_submission( pred_path='predictions.csv' )\n",
    "\n",
    "# # Print score\n",
    "# print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a bag-of-words in scikit-learn\n",
    "\n",
    "In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.\n",
    "\n",
    "You will focus on one feature only, the Position_Extra column, which describes any additional information not captured by the Position_Type label.\n",
    "\n",
    "For example, in the Shell you can check out the budget item in row 8960 of the data using df.loc[8960]. Looking at the output reveals that this Object_Description is overtime pay. For who? The Position Type is merely \"other\", but the Position Extra elaborates: \"BUS DRIVER\". Explore the column further to see more instances. It has a lot of NaN values.\n",
    "\n",
    "Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.\n",
    "\n",
    "For comparison purposes, the first 15 tokens of vec_basic, which splits df.Position_Extra into tokens when it encounters only whitespace characters, have been printed along with the length of the representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('' , inplace = True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern =TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating only alpha-numeric characters as tokens gives you a smaller number of more meaningful tokens. You've got bag-of-words in the bag!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining text columns for tokenization\n",
    "\n",
    "In order to get a bag-of-words representation for all of the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.\n",
    "\n",
    "In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. CountVectorizer expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.\n",
    "\n",
    "In this exercise, you'll complete the function definition combine_text_columns(). When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method.\n",
    "\n",
    "Note that the function uses NUMERIC_COLUMNS and LABELS to determine which columns to drop. These lists have been loaded into the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "INDEX_COLUMN = ['Unnamed: 0']\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS +  INDEX_COLUMN):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    print(text_data.columns)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Object_Description', 'Text_2', 'SubFund_Description',\n",
      "       'Job_Title_Description', 'Text_3', 'Text_4', 'Sub_Object_Description',\n",
      "       'Location_Description', 'Function_Description',\n",
      "       'Facility_or_Department', 'Position_Extra', 'Program_Description',\n",
      "       'Fund_Description', 'Text_1'],\n",
      "      dtype='object')\n",
      "There are 4757 tokens in the dataset\n",
      "There are 3284 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FTE', 'Total']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERIC_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Function',\n",
       " 'Use',\n",
       " 'Sharing',\n",
       " 'Reporting',\n",
       " 'Student_Type',\n",
       " 'Position_Type',\n",
       " 'Object_Type',\n",
       " 'Pre_K',\n",
       " 'Operating_Status']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import other necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Split and select numeric data only, no nans \n",
    "X_train, X_test, y_train, y_test = train_test_split( sample_df[ ['numeric'] ]  ,\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('clf', OneVsRestClassifier( LogisticRegression() ))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - numeric, no nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Imputer object\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Create training and test sets using only numeric data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Insantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('imp', Imputer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit( X_train , y_train )\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score( X_test , y_test )\n",
    "print(\"\\nAccuracy on sample data - all numeric, incl nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split out only the text data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[ 'text' ],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('vec', CountVectorizer() ),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit( X_train , y_train\n",
    ")\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score( X_test , y_test )\n",
    "print(\"\\nAccuracy on sample data - just text data: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# Print head to check results\n",
    "print('Text Data')\n",
    "print(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ( 'vectorizer', CountVectorizer() )\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns , validate =False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train , y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import random forest classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add model step to pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators =15) )\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate the CountVectorizer: text_features\n",
    "text_features = CountVectorizer( token_pattern=TOKENS_ALPHANUMERIC  )\n",
    "\n",
    "# Fit text_features to the text vector\n",
    "text_features.fit(text_vector)\n",
    "\n",
    "# Print the first 10 tokens\n",
    "print(text_features.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import other preprocessing modules\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Select 300 best features\n",
    "chi_k = 300\n",
    "\n",
    "# Import functional utilities\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Perform preprocessing\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range= (1,2) )),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1, 2))),  \n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree =2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Get text data: text_data\n",
    "text_data = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)' \n",
    "\n",
    "# Instantiate the HashingVectorizer: hashing_vec\n",
    "hashing_vec = HashingVectorizer(token_pattern = TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit and transform the Hashing Vectorizer\n",
    "hashed_text = hashing_vec.fit_transform(text_data)\n",
    "\n",
    "# Create DataFrame and print the head\n",
    "hashed_df = pd.DataFrame(hashed_text.data)\n",
    "print(hashed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the hashing vectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Instantiate the winning model pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                     non_negative=True, norm=None, binary=False,\n",
    "                                                     ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
